<!DOCTYPE html>
<html lang="en-us" dir="ltr">

<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
  <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=2.5">
<title>Topic modeling with Gensim | kbabuji</title>
    <link rel="stylesheet" href="/css/main.css">
      <script src="/js/main.js"></script>
  <meta itemprop="name" content="Topic modeling with Gensim">
  <meta itemprop="description" content="Like unlocking hidden themes in a great novel, topic modeling unveils the unspoken threads in vast datasets. From scikit-learn’s reliable tools to gensim’s transformative power, join a journey into the art of teaching machines to understand text.">
  <meta itemprop="datePublished" content="2017-03-26T00:00:00-05:00">
  <meta itemprop="dateModified" content="2017-03-26T00:00:00-05:00">
  <meta itemprop="wordCount" content="908">
  <meta itemprop="keywords" content="gensim,topic-modeling"><meta property="og:url" content="http://localhost:1313/articles/topic-modeling-with-gensim/">
  <meta property="og:site_name" content="kbabuji">
  <meta property="og:title" content="Topic modeling with Gensim">
  <meta property="og:description" content="Like unlocking hidden themes in a great novel, topic modeling unveils the unspoken threads in vast datasets. From scikit-learn’s reliable tools to gensim’s transformative power, join a journey into the art of teaching machines to understand text.">
  <meta property="og:locale" content="en_us">
  <meta property="og:type" content="article">
    <meta property="article:section" content="articles">
    <meta property="article:published_time" content="2017-03-26T00:00:00-05:00">
    <meta property="article:modified_time" content="2017-03-26T00:00:00-05:00">
    <meta property="article:tag" content="Gensim">
    <meta property="article:tag" content="NLP">
    <meta property="article:tag" content="Topic-Modeling">
<link rel="shortcut icon" href="/favicon.ico">
<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/site.webmanifest">
<style>
    @import url('https://fonts.googleapis.com/css2?family=Montserrat:ital,wght@0,100..900;1,100..900&display=swap');
</style>
</head>

<body>
  <header class="navbar">
    <div class="masthead">
    <h2 ><a class="site-title" href="/">kbabuji</a></h2>
    <nav class="nav-links">
        <a href="/about">About</a>
        <a href="/articles">Archives</a>
        <a href="/categories">Categories</a>
    </nav>
</div>
  </header>
  <main class="wrapper">
    
<article class="article-container">
    
    <header class="article-header">
        <div class="category">AI &amp; ML</div>
        <h1 class="title">Topic modeling with Gensim</h1>
        <p class="description">Like unlocking hidden themes in a great novel, topic modeling unveils the unspoken threads in vast datasets. From scikit-learn’s reliable tools to gensim’s transformative power, join a journey into the art of teaching machines to understand text.</p>
        <div class="meta">
            <time datetime="2017-03-26">
                March 26, 2017
            </time>
        </div>
    </header>
    <div class="minimal-divider"></div>

    
    <div class="content">
        <p>I first started doing topic modeling when I used to play around with the <a href="https://www.kaggle.com/benhamner/nips-papers">nips dataset</a>. The first time I tried it, I used scikit-learn for this. I used LDA and NMF for this, and I received results that I was happy with. In this way, I think <a href="http://scikit-learn.org/stable/">scikit-learn</a> is one of the most appropriate tools available for exploratory data science tasks. But I had bigger plans, of tackling even bigger datasets. Then I got introduced to another python library <a href="https://radimrehurek.com/gensim/index.html">gensim</a> which is focused on topic modeling. Among many features it provides, it includes transformations such as <em>online</em> LDA, LSA and HDP, and wrappers to other popular libraries like scikit-learn, <a href="http://hunch.net/~vw/">vowpal wabbit</a>, and <a href="http://mallet.cs.umass.edu/">Mallet</a>.</p>
<p>The code can be viewed at my <a href="https://github.com/krispingal/topic_modeling">Github repository</a>.</p>
<p>While numpy and scipy comes along with gensim when you install it via <code>pip install -U gensim</code>, having <a href="http://www.nltk.org/">nltk</a> installed also might come in handy if you decide to perform lemmatization or stemming. Gensim does provide Porter stemming but nltk does provide many other features as well. It is also recommended to have a blas/laplack library such as <a href="http://www.openblas.net/">OpenBlas</a>, <a href="http://math-atlas.sourceforge.net/">Atlas</a> or <a href="https://software.intel.com/en-us/intel-mkl">intel MKL</a>.</p>
<h2 id="twenty-newsgroup">
  Twenty Newsgroup
  <a class="anchor" href="#twenty-newsgroup" aria-label="Link to section - Twenty Newsgroup">#</a>
</h2>

<p>I started out experiments on gensim with the <a href="https://archive.ics.uci.edu/ml/datasets/Twenty+Newsgroups">20 newsgroup dataset</a>, which is a collection of around 20,000 mails from different subscriptions. They will contain email headers, which can be stripped in your pre-processing. These 20 newgroup emails will be present in 20 folders, so you will have to do a directory walk and process each email. Once your pre-processing, that may involve lemmatization, stemming and stop-word removal, is complete you can provide the document or in this case emails to gensim, to be converted to bag-of-words representation. The resulting corpus you create can be &ldquo;streamed&rdquo; to subsequent gensim transformations, which just means gensim will work on documents one-by-one. This is memory efficient and means that you can perform topic modeling on large datasets like Wikipedia dump, on an average machine. The whole folder will be around 47 MB and this is a relatively
very small dataset.</p>
<p>Below is a bare-bones version of code for pre-processing your data:</p>
<div class="highlight"><pre tabindex="0" style="color:#cad3f5;background-color:#24273a;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#8bd5ca">import</span> <span style="color:#f5a97f">os</span>
</span></span><span style="display:flex;"><span><span style="color:#8bd5ca">import</span> <span style="color:#f5a97f">logging</span>
</span></span><span style="display:flex;"><span><span style="color:#8bd5ca">import</span> <span style="color:#f5a97f">gensim</span>
</span></span><span style="display:flex;"><span><span style="color:#8bd5ca">from</span> <span style="color:#f5a97f">gensim.utils</span> <span style="color:#8bd5ca">import</span> tokenize
</span></span><span style="display:flex;"><span><span style="color:#8bd5ca">from</span> <span style="color:#f5a97f">gensim.corpora</span> <span style="color:#8bd5ca">import</span> Dictionary
</span></span><span style="display:flex;"><span><span style="color:#8bd5ca">from</span> <span style="color:#f5a97f">nltk.corpus</span> <span style="color:#8bd5ca">import</span> stopwords
</span></span><span style="display:flex;"><span><span style="color:#8bd5ca">from</span> <span style="color:#f5a97f">itertools</span> <span style="color:#8bd5ca">import</span> dropwhile
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>logging<span style="color:#91d7e3;font-weight:bold">.</span>basicConfig(<span style="color:#91d7e3">format</span><span style="color:#91d7e3;font-weight:bold">=</span><span style="color:#a6da95">&#39;</span><span style="color:#a6da95">%(asctime)s</span><span style="color:#a6da95"> : </span><span style="color:#a6da95">%(levelname)s</span><span style="color:#a6da95"> : </span><span style="color:#a6da95">%(message)s</span><span style="color:#a6da95">&#39;</span>, level<span style="color:#91d7e3;font-weight:bold">=</span>logging<span style="color:#91d7e3;font-weight:bold">.</span>INFO)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#a6da95">&#34;&#34;&#34; iterate through directories by a walk&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span><span style="color:#c6a0f6">def</span> <span style="color:#8aadf4">iter_docs</span>(topdir, stoplist):
</span></span><span style="display:flex;"><span>    <span style="color:#c6a0f6">for</span> root, subdirs, files <span style="color:#91d7e3;font-weight:bold">in</span> os<span style="color:#91d7e3;font-weight:bold">.</span>walk(topdir):
</span></span><span style="display:flex;"><span>        <span style="color:#c6a0f6">for</span> filename <span style="color:#91d7e3;font-weight:bold">in</span> files:
</span></span><span style="display:flex;"><span>            file_path <span style="color:#91d7e3;font-weight:bold">=</span> os<span style="color:#91d7e3;font-weight:bold">.</span>path<span style="color:#91d7e3;font-weight:bold">.</span>join(root, filename)
</span></span><span style="display:flex;"><span>            fin <span style="color:#91d7e3;font-weight:bold">=</span> <span style="color:#91d7e3">open</span>(file_path, <span style="color:#a6da95">&#39;rb&#39;</span>)
</span></span><span style="display:flex;"><span>            str_list <span style="color:#91d7e3;font-weight:bold">=</span> []
</span></span><span style="display:flex;"><span>            <span style="color:#c6a0f6">for</span> line <span style="color:#91d7e3;font-weight:bold">in</span> dropwhile(isHeader, fin):
</span></span><span style="display:flex;"><span>               str_list<span style="color:#91d7e3;font-weight:bold">.</span>append(line)
</span></span><span style="display:flex;"><span>            text <span style="color:#91d7e3;font-weight:bold">=</span> <span style="color:#a6da95">&#39;&#39;</span><span style="color:#91d7e3;font-weight:bold">.</span>join(str_list)
</span></span><span style="display:flex;"><span>            fin<span style="color:#91d7e3;font-weight:bold">.</span>close()
</span></span><span style="display:flex;"><span>            <span style="color:#c6a0f6">yield</span> (x <span style="color:#c6a0f6">for</span> x <span style="color:#91d7e3;font-weight:bold">in</span> gensim<span style="color:#91d7e3;font-weight:bold">.</span>utils<span style="color:#91d7e3;font-weight:bold">.</span>tokenize(text, lowercase<span style="color:#91d7e3;font-weight:bold">=</span><span style="color:#f5a97f">True</span>, deacc<span style="color:#91d7e3;font-weight:bold">=</span><span style="color:#f5a97f">True</span>, errors<span style="color:#91d7e3;font-weight:bold">=</span><span style="color:#a6da95">&#34;ignore&#34;</span>)
</span></span><span style="display:flex;"><span>                                                    <span style="color:#c6a0f6">if</span> x <span style="color:#91d7e3;font-weight:bold">not</span> <span style="color:#91d7e3;font-weight:bold">in</span> stoplist)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#c6a0f6">class</span> <span style="color:#eed49f">OnlineCorpus</span>(<span style="color:#91d7e3">object</span>):
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#c6a0f6">def</span> <span style="color:#8aadf4">__init__</span>(<span style="color:#91d7e3">self</span>, topdir, stoplist):
</span></span><span style="display:flex;"><span>        <span style="color:#91d7e3">self</span><span style="color:#91d7e3;font-weight:bold">.</span>topdir <span style="color:#91d7e3;font-weight:bold">=</span> topdir
</span></span><span style="display:flex;"><span>        <span style="color:#91d7e3">self</span><span style="color:#91d7e3;font-weight:bold">.</span>stoplist <span style="color:#91d7e3;font-weight:bold">=</span> stoplist
</span></span><span style="display:flex;"><span>        <span style="color:#91d7e3">self</span><span style="color:#91d7e3;font-weight:bold">.</span>dictionary <span style="color:#91d7e3;font-weight:bold">=</span> Dictionary(iter_docs(topdir,stoplist))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#c6a0f6">def</span> <span style="color:#8aadf4">__iter__</span>(<span style="color:#91d7e3">self</span>):
</span></span><span style="display:flex;"><span>        <span style="color:#c6a0f6">for</span> tokens <span style="color:#91d7e3;font-weight:bold">in</span> iter_docs(<span style="color:#91d7e3">self</span><span style="color:#91d7e3;font-weight:bold">.</span>topdir, <span style="color:#91d7e3">self</span><span style="color:#91d7e3;font-weight:bold">.</span>stoplist):
</span></span><span style="display:flex;"><span>            <span style="color:#c6a0f6">yield</span> <span style="color:#91d7e3">self</span><span style="color:#91d7e3;font-weight:bold">.</span>dictionary<span style="color:#91d7e3;font-weight:bold">.</span>doc2bow(tokens)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>TEXTS_DIR <span style="color:#91d7e3;font-weight:bold">=</span> <span style="color:#a6da95">&#34;../Data/20_newsgroups&#34;</span>
</span></span><span style="display:flex;"><span>MODELS_DIR <span style="color:#91d7e3;font-weight:bold">=</span> <span style="color:#a6da95">&#34;../Data/models&#34;</span>
</span></span><span style="display:flex;"><span>stoplist <span style="color:#91d7e3;font-weight:bold">=</span> <span style="color:#91d7e3">set</span>(stopwords<span style="color:#91d7e3;font-weight:bold">.</span>words(<span style="color:#a6da95">&#34;english&#34;</span>))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>corpus <span style="color:#91d7e3;font-weight:bold">=</span> OnlineCorpus(TEXTS_DIR, stoplist)
</span></span><span style="display:flex;"><span>corpus<span style="color:#91d7e3;font-weight:bold">.</span>dictionary<span style="color:#91d7e3;font-weight:bold">.</span>save(os<span style="color:#91d7e3;font-weight:bold">.</span>path<span style="color:#91d7e3;font-weight:bold">.</span>join(MODELS_DIR, <span style="color:#a6da95">&#39;twentyNewsGroup.dict&#39;</span>))
</span></span><span style="display:flex;"><span>gensim<span style="color:#91d7e3;font-weight:bold">.</span>corpora<span style="color:#91d7e3;font-weight:bold">.</span>MmCorpus<span style="color:#91d7e3;font-weight:bold">.</span>serialize(os<span style="color:#91d7e3;font-weight:bold">.</span>path<span style="color:#91d7e3;font-weight:bold">.</span>join(MODELS_DIR, <span style="color:#a6da95">&#39;corpora.mm&#39;</span>), corpus)
</span></span></code></pre></div><p>It is also trivial to provide gensim&rsquo;s methods with a corpus that has been tf-idf transformed. Do note that, in case you hold out some of your dataset for later, you will have to do the same transformations you did on the training data, otherwise the results might end up bad.</p>
<p>Gensim also provides algorithms that will utilize multiple cores in your machine to be more efficient. There is also a distributed implementation of LDA and LSA that gensim provides which is very useful while dealing with very big datasets. While I have created a <a href="https://github.com/krispingal/topic_modeling/blob/master/20_newsgroup/lda_benchmark_20ng.ipynb">jupyter notebook</a> that benchmarks the performance of gensim&rsquo;s methods, do note that much newer versions of gensim would have better performance.</p>
<p>The below code is a bare-bones code for gensim after you have completed pre-processing:</p>
<div class="highlight" id="run"><pre tabindex="0" style="color:#cad3f5;background-color:#24273a;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#8087a2"> 1</span><span><span style="color:#8bd5ca">import</span> <span style="color:#f5a97f">os</span>
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#8087a2"> 2</span><span><span style="color:#8bd5ca">from</span> <span style="color:#f5a97f">gensim</span> <span style="color:#8bd5ca">import</span> corpora, models
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#8087a2"> 3</span><span>
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#8087a2"> 4</span><span>MODELS_DIR <span style="color:#91d7e3;font-weight:bold">=</span> <span style="color:#a6da95">&#34;../Data/models&#34;</span>
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#8087a2"> 5</span><span>num_topics <span style="color:#91d7e3;font-weight:bold">=</span> <span style="color:#f5a97f">10</span>
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#8087a2"> 6</span><span>dictionary <span style="color:#91d7e3;font-weight:bold">=</span> corpora<span style="color:#91d7e3;font-weight:bold">.</span>Dictionary<span style="color:#91d7e3;font-weight:bold">.</span>load(os<span style="color:#91d7e3;font-weight:bold">.</span>path<span style="color:#91d7e3;font-weight:bold">.</span>join(MODELS_DIR,<span style="color:#a6da95">&#39;twentyNewsGroup.dict&#39;</span>))
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#8087a2"> 7</span><span>corpus <span style="color:#91d7e3;font-weight:bold">=</span> corpora<span style="color:#91d7e3;font-weight:bold">.</span>MmCorpus(os<span style="color:#91d7e3;font-weight:bold">.</span>path<span style="color:#91d7e3;font-weight:bold">.</span>join(MODELS_DIR, <span style="color:#a6da95">&#39;corpora.mm&#39;</span>))
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#8087a2"> 8</span><span>lda <span style="color:#91d7e3;font-weight:bold">=</span> models<span style="color:#91d7e3;font-weight:bold">.</span>LdaModel(corpus<span style="color:#91d7e3;font-weight:bold">=</span>corpus, id2word<span style="color:#91d7e3;font-weight:bold">=</span>dictionary, num_topics<span style="color:#91d7e3;font-weight:bold">=</span>num_topics)
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#8087a2"> 9</span><span>lda<span style="color:#91d7e3;font-weight:bold">.</span>print_topics(num_topics<span style="color:#91d7e3;font-weight:bold">=</span>num_topics, num_words<span style="color:#91d7e3;font-weight:bold">=</span><span style="color:#f5a97f">10</span>)
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#8087a2">10</span><span>lda<span style="color:#91d7e3;font-weight:bold">.</span>save(os<span style="color:#91d7e3;font-weight:bold">.</span>path<span style="color:#91d7e3;font-weight:bold">.</span>join(MODELS_DIR, <span style="color:#a6da95">&#39;twentyNewsGroups.lda&#39;</span>))
</span></span></code></pre></div><h2 id="enron-dataset">
  Enron dataset
  <a class="anchor" href="#enron-dataset" aria-label="Link to section - Enron dataset">#</a>
</h2>

<p>Once I started benchmarking the performance of gensim on the twenty newsgroup dataset I realized that there is not enough data to see a clear distinction between the two, and what I really wanted to know was how they would perform when dealing with a bigger dataset. For this reason, I next tried my hand on the <a href="https://www.kaggle.com/wcukierski/enron-email-dataset">Enron dataset</a>, which is a dataset containing around 500,000 emails between employees of Enron, before it went bankrupt.</p>
<p>One of the earliest gripes I had with gensim was that it did not have enough documentation in my opinion. While trying to figure out how some methods worked, by reading the source code from <a href="https://github.com/RaRe-Technologies/gensim">gensim&rsquo;s Github repository</a>, I discovered a folder containing many jupyter notebooks that demonstrated many recipes. Apart from this, the <a href="https://groups.google.com/forum/#!forum/gensim">google group</a> is also active and the posts there would also give you directions.</p>
<p>Overall I would say, gensim&rsquo;s usage has increased and it has continued bringing more and more useful functionalities, to the board. I have noticed that gensim&rsquo;s performance does <em>not increase as much as one would expect</em> even if we provide more cores or more machines to the algorithm. I am expecting this to be fixed soon by the developers as they continue to optimize the code. Another thing I have noted is the effectiveness of the random state. I am expecting that by providing the same random state to the LDA, provided every other parameter remains the same, I would be getting back the same model. As far as I can see, this is not happening.</p>
<h2 id="recommended-reading">
  Recommended reading
  <a class="anchor" href="#recommended-reading" aria-label="Link to section - Recommended reading">#</a>
</h2>

<ul>
<li><a href="http://blog.echen.me/2011/08/22/introduction-to-latent-dirichlet-allocation/">An introduction to LDA</a></li>
<li><a href="https://github.com/RaRe-Technologies/gensim/tree/develop/docs/notebooks">gensim&rsquo;s jupyter docs that cover important points</a></li>
</ul>
    </div>

    
    <footer class="article-footer">
        <nav class="article-tags">
  <ul class="tags" style="padding-left: 0px;padding-top:10px">
      <li><a href="/tags/gensim/">Gensim</a></li>
      <li><a href="/tags/nlp/">NLP</a></li>
      <li><a href="/tags/topic-modeling/">Topic-Modeling</a></li>
  </ul>

        </nav>
    </footer>
</article>
<aside class="related-posts">
</aside>
  </main>
  <footer class="footer-nav">
<div class="footer-icons">
    <a href="/" aria-label="Home"><svg class="icon" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><path d="M575.8 255.5c0 18-15 32.1-32 32.1l-32 0 .7 160.2c0 2.7-.2 5.4-.5 8.1l0 16.2c0 22.1-17.9 40-40 40l-16 0c-1.1 0-2.2 0-3.3-.1c-1.4 .1-2.8 .1-4.2 .1L416 512l-24 0c-22.1 0-40-17.9-40-40l0-24 0-64c0-17.7-14.3-32-32-32l-64 0c-17.7 0-32 14.3-32 32l0 64 0 24c0 22.1-17.9 40-40 40l-24 0-31.9 0c-1.5 0-3-.1-4.5-.2c-1.2 .1-2.4 .2-3.6 .2l-16 0c-22.1 0-40-17.9-40-40l0-112c0-.9 0-1.9 .1-2.8l0-69.7-32 0c-18 0-32-14-32-32.1c0-9 3-17 10-24L266.4 8c7-7 15-8 22-8s15 2 21 7L564.8 231.5c8 7 12 15 11 24z"/></svg></a>
    <a href="https://github.com/krispingal" target="_blank" aria-label="GitHub"><svg class="icon" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3 .3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5 .3-6.2 2.3zm44.2-1.7c-2.9 .7-4.9 2.6-4.6 4.9 .3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3 .7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3 .3 2.9 2.3 3.9 1.6 1 3.6 .7 4.3-.7 .7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3 .7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3 .7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg></a>
    <a href="https://linkedin.com/in/krishna-babuji" target="_blank" aria-label="LinkedIn"><svg class="icon" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"/></svg></a>
    <a href="mailto:krishna.pingal@gmail.com" aria-label="Email"><svg class="icon" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M48 64C21.5 64 0 85.5 0 112c0 15.1 7.1 29.3 19.2 38.4L236.8 313.6c11.4 8.5 27 8.5 38.4 0L492.8 150.4c12.1-9.1 19.2-23.3 19.2-38.4c0-26.5-21.5-48-48-48L48 64zM0 176L0 384c0 35.3 28.7 64 64 64l384 0c35.3 0 64-28.7 64-64l0-208L294.4 339.2c-22.8 17.1-54 17.1-76.8 0L0 176z"/></svg></a>
</div>
<p class="footer-copyright">© 2016 &ndash; 2025 kbabuji. All rights reserved.</p>

  </footer>
</body>

</html>