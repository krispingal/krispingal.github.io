<!DOCTYPE html>
<html lang="en-us" dir="ltr">

<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
  <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=2.5">
  <meta name="description" content="Like unlocking hidden themes in a great novel, topic modeling unveils the unspoken threads in vast datasets. From scikit-learn’s reliable tools to gensim’s transformative power, join a journey into the art of teaching machines to understand text.">
<title>Topic modeling with Gensim | kbabuji</title>
    <link rel="stylesheet" href="/css/main.css">
      <script src="/js/main.js"></script>
  <meta itemprop="name" content="Topic modeling with Gensim">
  <meta itemprop="description" content="Like unlocking hidden themes in a great novel, topic modeling unveils the unspoken threads in vast datasets. From scikit-learn’s reliable tools to gensim’s transformative power, join a journey into the art of teaching machines to understand text.">
  <meta itemprop="datePublished" content="2017-03-26T00:00:00-05:00">
  <meta itemprop="dateModified" content="2017-03-26T00:00:00-05:00">
  <meta itemprop="wordCount" content="908">
  <meta itemprop="keywords" content="gensim,topic-modeling"><meta property="og:url" content="http://localhost:1313/articles/topic-modeling-with-gensim/">
  <meta property="og:site_name" content="kbabuji">
  <meta property="og:title" content="Topic modeling with Gensim">
  <meta property="og:description" content="Like unlocking hidden themes in a great novel, topic modeling unveils the unspoken threads in vast datasets. From scikit-learn’s reliable tools to gensim’s transformative power, join a journey into the art of teaching machines to understand text.">
  <meta property="og:locale" content="en_us">
  <meta property="og:type" content="article">
    <meta property="article:section" content="articles">
    <meta property="article:published_time" content="2017-03-26T00:00:00-05:00">
    <meta property="article:modified_time" content="2017-03-26T00:00:00-05:00">
    <meta property="article:tag" content="Gensim">
    <meta property="article:tag" content="NLP">
    <meta property="article:tag" content="Topic-Modeling">
<link rel="shortcut icon" href="/favicon.ico">
<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/site.webmanifest">
<style>
    @import url('https://fonts.googleapis.com/css2?family=Montserrat:ital,wght@0,100..900;1,100..900&display=swap');
</style>
</head>

<body>
  <header class="navbar">
    <div class="masthead">
    <h2 ><a class="site-title" href="/">kbabuji</a></h2>
    <nav class="nav-links">
        <a href="/about">About</a>
        <a href="/articles">Archives</a>
        <a href="/categories">Categories</a>
    </nav>
</div>
  </header>
  <main class="wrapper">
    
<article class="article-container">
    
    <header class="article-header">
        <div class="category">AI &amp; ML</div>
        <h1 class="title">Topic modeling with Gensim</h1>
        <p class="description">Like unlocking hidden themes in a great novel, topic modeling unveils the unspoken threads in vast datasets. From scikit-learn’s reliable tools to gensim’s transformative power, join a journey into the art of teaching machines to understand text.</p>
        <div class="meta">
            <time datetime="2017-03-26">
                March 26, 2017
            </time>
        </div>
    </header>
    <div class="minimal-divider"></div>

    
    <div class="content">
        <p>I first started doing topic modeling when I used to play around with the <a href="https://www.kaggle.com/benhamner/nips-papers">nips dataset</a>. The first time I tried it, I used scikit-learn for this. I used LDA and NMF for this, and I received results that I was happy with. In this way, I think <a href="http://scikit-learn.org/stable/">scikit-learn</a> is one of the most appropriate tools available for exploratory data science tasks. But I had bigger plans, of tackling even bigger datasets. Then I got introduced to another python library <a href="https://radimrehurek.com/gensim/index.html">gensim</a> which is focused on topic modeling. Among many features it provides, it includes transformations such as <em>online</em> LDA, LSA and HDP, and wrappers to other popular libraries like scikit-learn, <a href="http://hunch.net/~vw/">vowpal wabbit</a>, and <a href="http://mallet.cs.umass.edu/">Mallet</a>.</p>
<p>The code can be viewed at my <a href="https://github.com/krispingal/topic_modeling">Github repository</a>.</p>
<p>While numpy and scipy comes along with gensim when you install it via <code>pip install -U gensim</code>, having <a href="http://www.nltk.org/">nltk</a> installed also might come in handy if you decide to perform lemmatization or stemming. Gensim does provide Porter stemming but nltk does provide many other features as well. It is also recommended to have a blas/laplack library such as <a href="http://www.openblas.net/">OpenBlas</a>, <a href="http://math-atlas.sourceforge.net/">Atlas</a> or <a href="https://software.intel.com/en-us/intel-mkl">intel MKL</a>.</p>
<h2 id="twenty-newsgroup">
  Twenty Newsgroup
  <a class="anchor" href="#twenty-newsgroup" aria-label="Link to section - Twenty Newsgroup">#</a>
</h2>

<p>I started out experiments on gensim with the <a href="https://archive.ics.uci.edu/ml/datasets/Twenty+Newsgroups">20 newsgroup dataset</a>, which is a collection of around 20,000 mails from different subscriptions. They will contain email headers, which can be stripped in your pre-processing. These 20 newgroup emails will be present in 20 folders, so you will have to do a directory walk and process each email. Once your pre-processing, that may involve lemmatization, stemming and stop-word removal, is complete you can provide the document or in this case emails to gensim, to be converted to bag-of-words representation. The resulting corpus you create can be &ldquo;streamed&rdquo; to subsequent gensim transformations, which just means gensim will work on documents one-by-one. This is memory efficient and means that you can perform topic modeling on large datasets like Wikipedia dump, on an average machine. The whole folder will be around 47 MB and this is a relatively
very small dataset.</p>
<p>Below is a bare-bones version of code for pre-processing your data:</p>
<div class="highlight"><pre tabindex="0" style="color:#cad3f5;background-color:#24273a;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#8bd5ca">import</span> <span style="color:#f5a97f">os</span>
</span></span><span style="display:flex;"><span><span style="color:#8bd5ca">import</span> <span style="color:#f5a97f">logging</span>
</span></span><span style="display:flex;"><span><span style="color:#8bd5ca">import</span> <span style="color:#f5a97f">gensim</span>
</span></span><span style="display:flex;"><span><span style="color:#8bd5ca">from</span> <span style="color:#f5a97f">gensim.utils</span> <span style="color:#8bd5ca">import</span> tokenize
</span></span><span style="display:flex;"><span><span style="color:#8bd5ca">from</span> <span style="color:#f5a97f">gensim.corpora</span> <span style="color:#8bd5ca">import</span> Dictionary
</span></span><span style="display:flex;"><span><span style="color:#8bd5ca">from</span> <span style="color:#f5a97f">nltk.corpus</span> <span style="color:#8bd5ca">import</span> stopwords
</span></span><span style="display:flex;"><span><span style="color:#8bd5ca">from</span> <span style="color:#f5a97f">itertools</span> <span style="color:#8bd5ca">import</span> dropwhile
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>logging<span style="color:#91d7e3;font-weight:bold">.</span>basicConfig(<span style="color:#91d7e3">format</span><span style="color:#91d7e3;font-weight:bold">=</span><span style="color:#a6da95">&#39;</span><span style="color:#a6da95">%(asctime)s</span><span style="color:#a6da95"> : </span><span style="color:#a6da95">%(levelname)s</span><span style="color:#a6da95"> : </span><span style="color:#a6da95">%(message)s</span><span style="color:#a6da95">&#39;</span>, level<span style="color:#91d7e3;font-weight:bold">=</span>logging<span style="color:#91d7e3;font-weight:bold">.</span>INFO)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#a6da95">&#34;&#34;&#34; iterate through directories by a walk&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span><span style="color:#c6a0f6">def</span> <span style="color:#8aadf4">iter_docs</span>(topdir, stoplist):
</span></span><span style="display:flex;"><span>    <span style="color:#c6a0f6">for</span> root, subdirs, files <span style="color:#91d7e3;font-weight:bold">in</span> os<span style="color:#91d7e3;font-weight:bold">.</span>walk(topdir):
</span></span><span style="display:flex;"><span>        <span style="color:#c6a0f6">for</span> filename <span style="color:#91d7e3;font-weight:bold">in</span> files:
</span></span><span style="display:flex;"><span>            file_path <span style="color:#91d7e3;font-weight:bold">=</span> os<span style="color:#91d7e3;font-weight:bold">.</span>path<span style="color:#91d7e3;font-weight:bold">.</span>join(root, filename)
</span></span><span style="display:flex;"><span>            fin <span style="color:#91d7e3;font-weight:bold">=</span> <span style="color:#91d7e3">open</span>(file_path, <span style="color:#a6da95">&#39;rb&#39;</span>)
</span></span><span style="display:flex;"><span>            str_list <span style="color:#91d7e3;font-weight:bold">=</span> []
</span></span><span style="display:flex;"><span>            <span style="color:#c6a0f6">for</span> line <span style="color:#91d7e3;font-weight:bold">in</span> dropwhile(isHeader, fin):
</span></span><span style="display:flex;"><span>               str_list<span style="color:#91d7e3;font-weight:bold">.</span>append(line)
</span></span><span style="display:flex;"><span>            text <span style="color:#91d7e3;font-weight:bold">=</span> <span style="color:#a6da95">&#39;&#39;</span><span style="color:#91d7e3;font-weight:bold">.</span>join(str_list)
</span></span><span style="display:flex;"><span>            fin<span style="color:#91d7e3;font-weight:bold">.</span>close()
</span></span><span style="display:flex;"><span>            <span style="color:#c6a0f6">yield</span> (x <span style="color:#c6a0f6">for</span> x <span style="color:#91d7e3;font-weight:bold">in</span> gensim<span style="color:#91d7e3;font-weight:bold">.</span>utils<span style="color:#91d7e3;font-weight:bold">.</span>tokenize(text, lowercase<span style="color:#91d7e3;font-weight:bold">=</span><span style="color:#f5a97f">True</span>, deacc<span style="color:#91d7e3;font-weight:bold">=</span><span style="color:#f5a97f">True</span>, errors<span style="color:#91d7e3;font-weight:bold">=</span><span style="color:#a6da95">&#34;ignore&#34;</span>)
</span></span><span style="display:flex;"><span>                                                    <span style="color:#c6a0f6">if</span> x <span style="color:#91d7e3;font-weight:bold">not</span> <span style="color:#91d7e3;font-weight:bold">in</span> stoplist)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#c6a0f6">class</span> <span style="color:#eed49f">OnlineCorpus</span>(<span style="color:#91d7e3">object</span>):
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#c6a0f6">def</span> <span style="color:#8aadf4">__init__</span>(<span style="color:#91d7e3">self</span>, topdir, stoplist):
</span></span><span style="display:flex;"><span>        <span style="color:#91d7e3">self</span><span style="color:#91d7e3;font-weight:bold">.</span>topdir <span style="color:#91d7e3;font-weight:bold">=</span> topdir
</span></span><span style="display:flex;"><span>        <span style="color:#91d7e3">self</span><span style="color:#91d7e3;font-weight:bold">.</span>stoplist <span style="color:#91d7e3;font-weight:bold">=</span> stoplist
</span></span><span style="display:flex;"><span>        <span style="color:#91d7e3">self</span><span style="color:#91d7e3;font-weight:bold">.</span>dictionary <span style="color:#91d7e3;font-weight:bold">=</span> Dictionary(iter_docs(topdir,stoplist))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#c6a0f6">def</span> <span style="color:#8aadf4">__iter__</span>(<span style="color:#91d7e3">self</span>):
</span></span><span style="display:flex;"><span>        <span style="color:#c6a0f6">for</span> tokens <span style="color:#91d7e3;font-weight:bold">in</span> iter_docs(<span style="color:#91d7e3">self</span><span style="color:#91d7e3;font-weight:bold">.</span>topdir, <span style="color:#91d7e3">self</span><span style="color:#91d7e3;font-weight:bold">.</span>stoplist):
</span></span><span style="display:flex;"><span>            <span style="color:#c6a0f6">yield</span> <span style="color:#91d7e3">self</span><span style="color:#91d7e3;font-weight:bold">.</span>dictionary<span style="color:#91d7e3;font-weight:bold">.</span>doc2bow(tokens)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>TEXTS_DIR <span style="color:#91d7e3;font-weight:bold">=</span> <span style="color:#a6da95">&#34;../Data/20_newsgroups&#34;</span>
</span></span><span style="display:flex;"><span>MODELS_DIR <span style="color:#91d7e3;font-weight:bold">=</span> <span style="color:#a6da95">&#34;../Data/models&#34;</span>
</span></span><span style="display:flex;"><span>stoplist <span style="color:#91d7e3;font-weight:bold">=</span> <span style="color:#91d7e3">set</span>(stopwords<span style="color:#91d7e3;font-weight:bold">.</span>words(<span style="color:#a6da95">&#34;english&#34;</span>))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>corpus <span style="color:#91d7e3;font-weight:bold">=</span> OnlineCorpus(TEXTS_DIR, stoplist)
</span></span><span style="display:flex;"><span>corpus<span style="color:#91d7e3;font-weight:bold">.</span>dictionary<span style="color:#91d7e3;font-weight:bold">.</span>save(os<span style="color:#91d7e3;font-weight:bold">.</span>path<span style="color:#91d7e3;font-weight:bold">.</span>join(MODELS_DIR, <span style="color:#a6da95">&#39;twentyNewsGroup.dict&#39;</span>))
</span></span><span style="display:flex;"><span>gensim<span style="color:#91d7e3;font-weight:bold">.</span>corpora<span style="color:#91d7e3;font-weight:bold">.</span>MmCorpus<span style="color:#91d7e3;font-weight:bold">.</span>serialize(os<span style="color:#91d7e3;font-weight:bold">.</span>path<span style="color:#91d7e3;font-weight:bold">.</span>join(MODELS_DIR, <span style="color:#a6da95">&#39;corpora.mm&#39;</span>), corpus)
</span></span></code></pre></div><p>It is also trivial to provide gensim&rsquo;s methods with a corpus that has been tf-idf transformed. Do note that, in case you hold out some of your dataset for later, you will have to do the same transformations you did on the training data, otherwise the results might end up bad.</p>
<p>Gensim also provides algorithms that will utilize multiple cores in your machine to be more efficient. There is also a distributed implementation of LDA and LSA that gensim provides which is very useful while dealing with very big datasets. While I have created a <a href="https://github.com/krispingal/topic_modeling/blob/master/20_newsgroup/lda_benchmark_20ng.ipynb">jupyter notebook</a> that benchmarks the performance of gensim&rsquo;s methods, do note that much newer versions of gensim would have better performance.</p>
<p>The below code is a bare-bones code for gensim after you have completed pre-processing:</p>
<div class="highlight" id="run"><pre tabindex="0" style="color:#cad3f5;background-color:#24273a;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#8087a2"> 1</span><span><span style="color:#8bd5ca">import</span> <span style="color:#f5a97f">os</span>
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#8087a2"> 2</span><span><span style="color:#8bd5ca">from</span> <span style="color:#f5a97f">gensim</span> <span style="color:#8bd5ca">import</span> corpora, models
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#8087a2"> 3</span><span>
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#8087a2"> 4</span><span>MODELS_DIR <span style="color:#91d7e3;font-weight:bold">=</span> <span style="color:#a6da95">&#34;../Data/models&#34;</span>
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#8087a2"> 5</span><span>num_topics <span style="color:#91d7e3;font-weight:bold">=</span> <span style="color:#f5a97f">10</span>
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#8087a2"> 6</span><span>dictionary <span style="color:#91d7e3;font-weight:bold">=</span> corpora<span style="color:#91d7e3;font-weight:bold">.</span>Dictionary<span style="color:#91d7e3;font-weight:bold">.</span>load(os<span style="color:#91d7e3;font-weight:bold">.</span>path<span style="color:#91d7e3;font-weight:bold">.</span>join(MODELS_DIR,<span style="color:#a6da95">&#39;twentyNewsGroup.dict&#39;</span>))
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#8087a2"> 7</span><span>corpus <span style="color:#91d7e3;font-weight:bold">=</span> corpora<span style="color:#91d7e3;font-weight:bold">.</span>MmCorpus(os<span style="color:#91d7e3;font-weight:bold">.</span>path<span style="color:#91d7e3;font-weight:bold">.</span>join(MODELS_DIR, <span style="color:#a6da95">&#39;corpora.mm&#39;</span>))
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#8087a2"> 8</span><span>lda <span style="color:#91d7e3;font-weight:bold">=</span> models<span style="color:#91d7e3;font-weight:bold">.</span>LdaModel(corpus<span style="color:#91d7e3;font-weight:bold">=</span>corpus, id2word<span style="color:#91d7e3;font-weight:bold">=</span>dictionary, num_topics<span style="color:#91d7e3;font-weight:bold">=</span>num_topics)
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#8087a2"> 9</span><span>lda<span style="color:#91d7e3;font-weight:bold">.</span>print_topics(num_topics<span style="color:#91d7e3;font-weight:bold">=</span>num_topics, num_words<span style="color:#91d7e3;font-weight:bold">=</span><span style="color:#f5a97f">10</span>)
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#8087a2">10</span><span>lda<span style="color:#91d7e3;font-weight:bold">.</span>save(os<span style="color:#91d7e3;font-weight:bold">.</span>path<span style="color:#91d7e3;font-weight:bold">.</span>join(MODELS_DIR, <span style="color:#a6da95">&#39;twentyNewsGroups.lda&#39;</span>))
</span></span></code></pre></div><h2 id="enron-dataset">
  Enron dataset
  <a class="anchor" href="#enron-dataset" aria-label="Link to section - Enron dataset">#</a>
</h2>

<p>Once I started benchmarking the performance of gensim on the twenty newsgroup dataset I realized that there is not enough data to see a clear distinction between the two, and what I really wanted to know was how they would perform when dealing with a bigger dataset. For this reason, I next tried my hand on the <a href="https://www.kaggle.com/wcukierski/enron-email-dataset">Enron dataset</a>, which is a dataset containing around 500,000 emails between employees of Enron, before it went bankrupt.</p>
<p>One of the earliest gripes I had with gensim was that it did not have enough documentation in my opinion. While trying to figure out how some methods worked, by reading the source code from <a href="https://github.com/RaRe-Technologies/gensim">gensim&rsquo;s Github repository</a>, I discovered a folder containing many jupyter notebooks that demonstrated many recipes. Apart from this, the <a href="https://groups.google.com/forum/#!forum/gensim">google group</a> is also active and the posts there would also give you directions.</p>
<p>Overall I would say, gensim&rsquo;s usage has increased and it has continued bringing more and more useful functionalities, to the board. I have noticed that gensim&rsquo;s performance does <em>not increase as much as one would expect</em> even if we provide more cores or more machines to the algorithm. I am expecting this to be fixed soon by the developers as they continue to optimize the code. Another thing I have noted is the effectiveness of the random state. I am expecting that by providing the same random state to the LDA, provided every other parameter remains the same, I would be getting back the same model. As far as I can see, this is not happening.</p>
<h2 id="recommended-reading">
  Recommended reading
  <a class="anchor" href="#recommended-reading" aria-label="Link to section - Recommended reading">#</a>
</h2>

<ul>
<li><a href="http://blog.echen.me/2011/08/22/introduction-to-latent-dirichlet-allocation/">An introduction to LDA</a></li>
<li><a href="https://github.com/RaRe-Technologies/gensim/tree/develop/docs/notebooks">gensim&rsquo;s jupyter docs that cover important points</a></li>
</ul>
    </div>

    
    <footer class="article-footer">
        <nav class="article-tags">
  <ul class="tags" style="padding-left: 0px;padding-top:10px">
      <li><a href="/tags/gensim/">Gensim</a></li>
      <li><a href="/tags/nlp/">NLP</a></li>
      <li><a href="/tags/topic-modeling/">Topic-Modeling</a></li>
  </ul>

        </nav>
    </footer>
</article>
<aside class="related-posts">
</aside>
<div class="content">
    <script src="https://giscus.app/client.js"
    data-repo="krispingal/krispingal.github.io"
    data-repo-id="R_kgDONNB2Ng"
    data-category="Announcements"
    data-category-id="DIC_kwDONNB2Ns4CmciE"
    data-mapping="url"
    data-reactions-enabled="1"
    data-emit-metadata="0"
    data-input-position="bottom"
    data-theme="catppuccin_latte"
    data-lang="en"
    data-loading="lazy"
    crossorigin="anonymous"
    async>
  </script>
</div>
  </main>
  <footer class="footer-nav">
<div class="footer-icons">
    <a href="/" aria-label="Home"><svg class="icon" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m21.743 12.331-9-10c-.379-.422-1.107-.422-1.486 0l-9 10a.998.998 0 0 0-.17 1.076c.16.361.518.593.913.593h2v7a1 1 0 0 0 1 1h3a1 1 0 0 0 1-1v-4h4v4a1 1 0 0 0 1 1h3a1 1 0 0 0 1-1v-7h2a.998.998 0 0 0 .743-1.669z"></path></svg></a>
    <a href="https://github.com/krispingal" target="_blank" aria-label="GitHub"><svg class="icon" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path fill-rule="evenodd" clip-rule="evenodd" d="M12.026 2c-5.509 0-9.974 4.465-9.974 9.974 0 4.406 2.857 8.145 6.821 9.465.499.09.679-.217.679-.481 0-.237-.008-.865-.011-1.696-2.775.602-3.361-1.338-3.361-1.338-.452-1.152-1.107-1.459-1.107-1.459-.905-.619.069-.605.069-.605 1.002.07 1.527 1.028 1.527 1.028.89 1.524 2.336 1.084 2.902.829.091-.645.351-1.085.635-1.334-2.214-.251-4.542-1.107-4.542-4.93 0-1.087.389-1.979 1.024-2.675-.101-.253-.446-1.268.099-2.64 0 0 .837-.269 2.742 1.021a9.582 9.582 0 0 1 2.496-.336 9.554 9.554 0 0 1 2.496.336c1.906-1.291 2.742-1.021 2.742-1.021.545 1.372.203 2.387.099 2.64.64.696 1.024 1.587 1.024 2.675 0 3.833-2.33 4.675-4.552 4.922.355.308.675.916.675 1.846 0 1.334-.012 2.41-.012 2.737 0 .267.178.577.687.479C19.146 20.115 22 16.379 22 11.974 22 6.465 17.535 2 12.026 2z"></path></svg></a>
    <a href="https://linkedin.com/in/krishna-babuji" target="_blank" aria-label="LinkedIn"><svg class="icon" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 3H4a1 1 0 0 0-1 1v16a1 1 0 0 0 1 1h16a1 1 0 0 0 1-1V4a1 1 0 0 0-1-1zM8.339 18.337H5.667v-8.59h2.672v8.59zM7.003 8.574a1.548 1.548 0 1 1 0-3.096 1.548 1.548 0 0 1 0 3.096zm11.335 9.763h-2.669V14.16c0-.996-.018-2.277-1.388-2.277-1.39 0-1.601 1.086-1.601 2.207v4.248h-2.667v-8.59h2.56v1.174h.037c.355-.675 1.227-1.387 2.524-1.387 2.704 0 3.203 1.778 3.203 4.092v4.71z"></path></svg></a>
    <a href="mailto:krishna.pingal@gmail.com" aria-label="Email"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" class="icon"><path d="M20 4H4a2 2 0 0 0-2 2v12a2 2 0 0 0 2 2h16a2 2 0 0 0 2-2V6a2 2 0 0 0-2-2zm0 4.7-8 5.334L4 8.7V6.297l8 5.333 8-5.333V8.7z"></path></svg></a>
    <a href="/articles/index.xml" aria-label="RSS"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" class="icon"><path d="M19 20.001C19 11.729 12.271 5 4 5v2c7.168 0 13 5.832 13 13.001h2z"></path><path d="M12 20.001h2C14 14.486 9.514 10 4 10v2c4.411 0 8 3.589 8 8.001z"></path><circle cx="6" cy="18" r="2"></circle></svg></a>
</div>
<p class="footer-copyright">© 2016 &ndash; 2025 kbabuji. All rights reserved.</p>

  </footer>
</body>

</html>